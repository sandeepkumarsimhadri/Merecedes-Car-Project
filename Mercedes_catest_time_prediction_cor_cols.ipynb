{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "55caf946",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from scipy.stats import f_oneway\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "435d66e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4209, 378)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mc_df=pd.read_csv('Mercedes (1).csv')\n",
    "mc_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "18573bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "init_cat_cols=[col for col in mc_df.columns if mc_df[col].dtype=='object']## Finding catg cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "afecd019",
   "metadata": {},
   "outputs": [],
   "source": [
    "init_con_cols=[col for col in mc_df.columns if mc_df[col].dtype=='int64' or mc_df[col].dtype=='float64']\n",
    "## Initial Data set cont columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "9a11920e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ID',\n",
       " 'X11',\n",
       " 'X93',\n",
       " 'X107',\n",
       " 'X233',\n",
       " 'X235',\n",
       " 'X268',\n",
       " 'X289',\n",
       " 'X290',\n",
       " 'X293',\n",
       " 'X297',\n",
       " 'X330',\n",
       " 'X347']"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Droping cont cols becoz of only single variable that too these are catg actually\n",
    "cols_drop_uniq_val=[]\n",
    "for col in con_cols:\n",
    "    if len(mc_df[col].value_counts()) ==1 or len(mc_df[col].value_counts())==mc_df.shape[0]:\n",
    "        cols_drop_uniq_val.append(col)\n",
    "cols_drop_uniq_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "418f2637",
   "metadata": {},
   "outputs": [],
   "source": [
    "#droping single value catg columns in datas et which is no use for model feeding\n",
    "mc_df.drop(columns=cols_drop_uniq_val,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "59f3293e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['y']"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con_cols=[col for col in mc_df.columns if mc_df[col].dtype=='int64' or mc_df[col].dtype=='float64']\n",
    "## Initial Data set cont columns\n",
    "con_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "0717cbac",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols=[col for col in mc_df.columns if mc_df[col].dtype=='object']## Finding catg cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "1bba6bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting all cont cols to catg cols\n",
    "#mc_df[con_cols]=mc_df[con_cols].astype(object)\n",
    "for col in con_cols:\n",
    "    if len(mc_df[col].value_counts().index) == 2:\n",
    "        mc_df[col]=mc_df[col].astype(object)\n",
    "    else:\n",
    "        mc_df[col]=mc_df[col].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "f538ba21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       130.81\n",
       "1        88.53\n",
       "2        76.26\n",
       "3        80.62\n",
       "4        78.02\n",
       "         ...  \n",
       "4204    107.39\n",
       "4205    108.77\n",
       "4206    109.22\n",
       "4207     87.48\n",
       "4208    110.85\n",
       "Name: y, Length: 4209, dtype: float64"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mc_df['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "1c68edc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mc_df['X15'])==mc_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "6714ba77",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=mc_df['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "3655adfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "      <th>col_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>X0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.128032e-24</td>\n",
       "      <td>X1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.930684e-196</td>\n",
       "      <td>X2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.251233e-36</td>\n",
       "      <td>X3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.920920e-02</td>\n",
       "      <td>X4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.035847e-04</td>\n",
       "      <td>X5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.615937e-06</td>\n",
       "      <td>X6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.269254e-14</td>\n",
       "      <td>X8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8.003760e-02</td>\n",
       "      <td>X10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5.364599e-09</td>\n",
       "      <td>X12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.730964e-03</td>\n",
       "      <td>X13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>7.691696e-37</td>\n",
       "      <td>X14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.337658e-01</td>\n",
       "      <td>X15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.490908e-03</td>\n",
       "      <td>X16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.765457e-25</td>\n",
       "      <td>X17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>9.076521e-01</td>\n",
       "      <td>X18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2.634366e-28</td>\n",
       "      <td>X19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>6.206424e-10</td>\n",
       "      <td>X20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>4.356294e-02</td>\n",
       "      <td>X21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>8.731436e-10</td>\n",
       "      <td>X22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            value col_name\n",
       "0    0.000000e+00       X0\n",
       "1    1.128032e-24       X1\n",
       "2   1.930684e-196       X2\n",
       "3    1.251233e-36       X3\n",
       "4    4.920920e-02       X4\n",
       "5    4.035847e-04       X5\n",
       "6    3.615937e-06       X6\n",
       "7    1.269254e-14       X8\n",
       "8    8.003760e-02      X10\n",
       "9    5.364599e-09      X12\n",
       "10   1.730964e-03      X13\n",
       "11   7.691696e-37      X14\n",
       "12   1.337658e-01      X15\n",
       "13   1.490908e-03      X16\n",
       "14   1.765457e-25      X17\n",
       "15   9.076521e-01      X18\n",
       "16   2.634366e-28      X19\n",
       "17   6.206424e-10      X20\n",
       "18   4.356294e-02      X21\n",
       "19   8.731436e-10      X22"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#performing anova to find out corelated columns\n",
    "def anova(col):\n",
    "    catg=mc_df[col].value_counts().index\n",
    "    res=f_oneway(*[mc_df[mc_df[col]==cat]['y'] for cat in catg])\n",
    "    return res[1],col\n",
    "\n",
    "\n",
    "cont_data_all_cols=[anova(col) for col in cat_cols]\n",
    "#cont_data_cor_cols\n",
    "anova_df=pd.DataFrame(cont_data_all_cols,columns =['value', 'col_name'])\n",
    "anova_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "ec89f6dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "250"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_cont_cols=anova_df[anova_df['value'] < 0.05]\n",
    "corr_cont_col_names=list(corr_cont_cols['col_name'])\n",
    "len(corr_cont_col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "313fec67",
   "metadata": {},
   "outputs": [],
   "source": [
    "mainfo_df=mc_df.copy()## Creating copy of DF for deleting unwanted columns\n",
    "mainfo_df.drop(columns=corr_cont_col_names,inplace=True)## Now this DF contains unwanted columns so that it can pass to next step\n",
    "ls_cols_remove=list(mainfo_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "3a68133a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X0</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X8</th>\n",
       "      <th>X12</th>\n",
       "      <th>X13</th>\n",
       "      <th>...</th>\n",
       "      <th>X371</th>\n",
       "      <th>X372</th>\n",
       "      <th>X373</th>\n",
       "      <th>X376</th>\n",
       "      <th>X377</th>\n",
       "      <th>X378</th>\n",
       "      <th>X379</th>\n",
       "      <th>X380</th>\n",
       "      <th>X382</th>\n",
       "      <th>X383</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>k</td>\n",
       "      <td>v</td>\n",
       "      <td>at</td>\n",
       "      <td>a</td>\n",
       "      <td>d</td>\n",
       "      <td>u</td>\n",
       "      <td>j</td>\n",
       "      <td>o</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>k</td>\n",
       "      <td>t</td>\n",
       "      <td>av</td>\n",
       "      <td>e</td>\n",
       "      <td>d</td>\n",
       "      <td>y</td>\n",
       "      <td>l</td>\n",
       "      <td>o</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>az</td>\n",
       "      <td>w</td>\n",
       "      <td>n</td>\n",
       "      <td>c</td>\n",
       "      <td>d</td>\n",
       "      <td>x</td>\n",
       "      <td>j</td>\n",
       "      <td>x</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>az</td>\n",
       "      <td>t</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>d</td>\n",
       "      <td>x</td>\n",
       "      <td>l</td>\n",
       "      <td>e</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>az</td>\n",
       "      <td>v</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>d</td>\n",
       "      <td>h</td>\n",
       "      <td>d</td>\n",
       "      <td>n</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4204</th>\n",
       "      <td>ak</td>\n",
       "      <td>s</td>\n",
       "      <td>as</td>\n",
       "      <td>c</td>\n",
       "      <td>d</td>\n",
       "      <td>aa</td>\n",
       "      <td>d</td>\n",
       "      <td>q</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4205</th>\n",
       "      <td>j</td>\n",
       "      <td>o</td>\n",
       "      <td>t</td>\n",
       "      <td>d</td>\n",
       "      <td>d</td>\n",
       "      <td>aa</td>\n",
       "      <td>h</td>\n",
       "      <td>h</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4206</th>\n",
       "      <td>ak</td>\n",
       "      <td>v</td>\n",
       "      <td>r</td>\n",
       "      <td>a</td>\n",
       "      <td>d</td>\n",
       "      <td>aa</td>\n",
       "      <td>g</td>\n",
       "      <td>e</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4207</th>\n",
       "      <td>al</td>\n",
       "      <td>r</td>\n",
       "      <td>e</td>\n",
       "      <td>f</td>\n",
       "      <td>d</td>\n",
       "      <td>aa</td>\n",
       "      <td>l</td>\n",
       "      <td>u</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4208</th>\n",
       "      <td>z</td>\n",
       "      <td>r</td>\n",
       "      <td>ae</td>\n",
       "      <td>c</td>\n",
       "      <td>d</td>\n",
       "      <td>aa</td>\n",
       "      <td>g</td>\n",
       "      <td>w</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4209 rows × 250 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      X0 X1  X2 X3 X4  X5 X6 X8 X12 X13  ... X371 X372 X373 X376 X377 X378  \\\n",
       "0      k  v  at  a  d   u  j  o   0   1  ...    0    0    0    0    1    0   \n",
       "1      k  t  av  e  d   y  l  o   0   0  ...    0    0    0    0    0    0   \n",
       "2     az  w   n  c  d   x  j  x   0   0  ...    0    0    0    0    0    0   \n",
       "3     az  t   n  f  d   x  l  e   0   0  ...    0    1    0    0    0    0   \n",
       "4     az  v   n  f  d   h  d  n   0   0  ...    1    0    0    0    0    0   \n",
       "...   .. ..  .. .. ..  .. .. ..  ..  ..  ...  ...  ...  ...  ...  ...  ...   \n",
       "4204  ak  s  as  c  d  aa  d  q   0   0  ...    0    0    0    0    0    0   \n",
       "4205   j  o   t  d  d  aa  h  h   0   0  ...    0    0    0    1    0    0   \n",
       "4206  ak  v   r  a  d  aa  g  e   1   1  ...    0    0    0    0    1    0   \n",
       "4207  al  r   e  f  d  aa  l  u   0   0  ...    0    0    0    0    0    0   \n",
       "4208   z  r  ae  c  d  aa  g  w   0   0  ...    0    0    0    0    0    0   \n",
       "\n",
       "     X379 X380 X382 X383  \n",
       "0       0    0    0    0  \n",
       "1       0    0    0    0  \n",
       "2       0    0    1    0  \n",
       "3       0    0    0    0  \n",
       "4       0    0    0    0  \n",
       "...   ...  ...  ...  ...  \n",
       "4204    0    0    0    0  \n",
       "4205    0    0    0    0  \n",
       "4206    0    0    0    0  \n",
       "4207    0    0    0    0  \n",
       "4208    0    0    0    0  \n",
       "\n",
       "[4209 rows x 250 columns]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mc_df.drop(columns=ls_cols_remove,inplace=True) ## Unwanted cols deleting and having only correlated cols\n",
    "mc_df## only Correlated cols in main DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "90016dc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3367, 250)"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(mc_df,y,random_state=49,test_size=0.2)\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "de25f99b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[col for col in mc_df.columns if mc_df[col].dtype=='int64' or mc_df[col].dtype=='float64']\n",
    "#Validating no cont cols in Data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "2f993871",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "250"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ful_cat_cols=[col for col in mc_df.columns if mc_df[col].dtype=='object']\n",
    "len(ful_cat_cols)\n",
    "#Validating all  cls in Data set are catg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "c928fdcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[ful_cat_cols].isnull().sum().any()## no missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "d3948064",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_encd_train= pd.get_dummies(x_train[ful_cat_cols])\n",
    "cat_encd_test=pd.get_dummies(x_test[ful_cat_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "c5c83c28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3367, 674), (842, 651))"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_encd_train.shape,cat_encd_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "9bcec701",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3367, 646)"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_encd_train_final,cat_encd_test_final=cat_encd_train.align(cat_encd_test,join='inner',axis=1)\n",
    "cat_encd_train_final.shape###aligning train & test data one hot encoded catg columns due to unqual no of columns i.e no of cilumns would differ for that we align to get same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "c007c8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtree_reg=DecisionTreeRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "1f6699ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor()"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtree_reg.fit(cat_encd_train_final,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "aa569571",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([106.52      , 109.21      ,  98.72      ,  98.765     ,\n",
       "        97.76      ,  90.11      , 112.8       ,  99.99      ,\n",
       "        75.05      ,  98.95      ,  97.55      , 108.3       ,\n",
       "       108.99      ,  92.65833333,  76.64      , 114.88      ,\n",
       "       113.31      ,  86.51      ,  98.61      , 106.67      ,\n",
       "        89.81      ,  93.12      ,  87.81      , 110.32      ,\n",
       "        98.88      ,  89.79      , 113.86      ,  91.62      ,\n",
       "       105.89      ,  89.46      ,  95.15      ,  93.45      ,\n",
       "        87.3       , 111.345     , 120.38      ,  78.225     ,\n",
       "        88.41      , 114.32      , 112.32      ,  87.05      ,\n",
       "        83.96      , 100.05      ,  89.97      ,  94.31      ,\n",
       "        92.54      , 116.2       ,  89.69      ,  93.27      ,\n",
       "        94.5       ,  93.295     ,  92.08      , 108.83      ,\n",
       "       103.06      ,  87.51      , 100.68      ,  90.04      ,\n",
       "        90.52      , 117.98      ,  96.41      , 103.96      ,\n",
       "       108.8       , 100.05      , 111.44      ,  93.97      ,\n",
       "       102.58      ,  91.63      , 103.77      , 115.16      ,\n",
       "       117.98      ,  98.88      ,  92.36      ,  93.91      ,\n",
       "       114.26      ,  91.99      , 108.68      , 118.44      ,\n",
       "        91.33      ,  87.57      ,  88.2       , 112.        ,\n",
       "        90.44      ,  88.51      , 105.25      ,  90.63      ,\n",
       "        90.8       ,  96.56      , 121.23      , 106.97      ,\n",
       "       102.6       ,  91.99      , 106.1       ,  98.76      ,\n",
       "        99.02      , 100.68      ,  90.78      ,  88.86      ,\n",
       "        75.54      ,  93.58      ,  94.62      ,  88.73      ,\n",
       "        98.95      , 111.44      , 100.32      ,  99.53      ,\n",
       "       109.43      ,  97.86      , 108.14      , 118.86      ,\n",
       "        83.67      ,  96.06      ,  88.38      ,  96.06      ,\n",
       "       112.12      ,  89.48      , 108.34      , 132.65      ,\n",
       "       107.85      , 101.96      , 121.6       ,  88.05      ,\n",
       "        96.48      ,  88.98      ,  92.22      , 115.72      ,\n",
       "       122.4       ,  89.6       , 109.49      ,  90.57      ,\n",
       "       110.43      ,  87.91      ,  77.5       , 115.95      ,\n",
       "       111.42      ,  93.635     , 100.54      ,  95.445     ,\n",
       "       109.28      ,  94.31      , 108.64      , 106.67      ,\n",
       "        88.1       , 115.22      , 128.58      ,  88.82      ,\n",
       "        92.04      , 114.51      ,  88.59      , 104.76      ,\n",
       "       113.87      ,  92.96      ,  99.52      ,  87.05      ,\n",
       "        81.06      ,  74.75      ,  89.35      , 114.25      ,\n",
       "        89.6       , 110.91      , 119.38      ,  89.13      ,\n",
       "       118.53      ,  93.45      , 108.03      , 112.94      ,\n",
       "       103.68      ,  76.44      , 129.45      , 116.08      ,\n",
       "        96.765     ,  92.6175    , 104.93      , 106.        ,\n",
       "        74.75      ,  90.35      , 113.67      ,  93.96      ,\n",
       "       112.44      , 101.9       , 112.06      ,  88.23      ,\n",
       "       104.49      ,  91.12      , 120.12      , 114.63      ,\n",
       "        74.77      ,  88.05      , 110.95      ,  88.03      ,\n",
       "        85.97      ,  90.86      , 109.97      ,  90.85      ,\n",
       "       114.6       ,  91.03      ,  91.99      ,  89.6       ,\n",
       "       115.32      ,  90.65      , 114.65      , 107.44      ,\n",
       "        88.2       , 113.75      ,  87.53      ,  91.35      ,\n",
       "       111.15      ,  87.94      , 114.07      ,  95.38      ,\n",
       "       102.66      , 105.79      ,  88.46      , 106.88      ,\n",
       "        92.53      , 121.15      ,  88.52      ,  94.39      ,\n",
       "        90.08      , 109.02      ,  86.41      ,  87.47      ,\n",
       "       111.1       ,  88.92      ,  77.68      , 117.07      ,\n",
       "        90.83      , 111.83666667,  99.47      ,  93.86      ,\n",
       "        94.35      , 109.05      ,  89.35      , 101.18      ,\n",
       "        94.56      ,  98.14      , 114.8       ,  99.78      ,\n",
       "       108.02      ,  88.61      ,  77.16      , 114.18      ,\n",
       "       100.33      ,  91.65      ,  88.81      , 116.34      ,\n",
       "       116.04      ,  95.01      , 116.16      , 127.27      ,\n",
       "       109.73      ,  87.51      ,  92.02      ,  78.71      ,\n",
       "       100.98      , 119.89      ,  88.12      ,  95.65      ,\n",
       "        75.9       ,  88.77      , 108.57      ,  96.51      ,\n",
       "       112.8       ,  90.84      ,  91.96      ,  74.75      ,\n",
       "        94.62      ,  88.91      , 114.18      ,  75.51      ,\n",
       "        87.58      , 119.57      ,  88.1       ,  90.35      ,\n",
       "       105.45      , 121.19      ,  92.55      , 108.64      ,\n",
       "        92.8       , 141.39      , 115.92      ,  95.71      ,\n",
       "        93.31      ,  89.21      ,  73.52      ,  90.8       ,\n",
       "        93.25      , 120.58      , 110.43      , 110.65      ,\n",
       "       134.26      ,  89.25      ,  92.34      , 102.97      ,\n",
       "        90.57      ,  88.2       ,  93.71      ,  88.14      ,\n",
       "       102.31      ,  95.5       ,  92.5       ,  90.27      ,\n",
       "        94.36      ,  96.79      , 107.13      ,  88.92      ,\n",
       "        91.01      , 111.345     , 104.42      ,  93.81      ,\n",
       "       117.32      , 101.47      , 110.47      , 103.71      ,\n",
       "        89.        , 104.6       , 111.1       , 107.39      ,\n",
       "        91.21      ,  97.28      ,  92.21      , 117.52      ,\n",
       "        93.38      ,  87.58      ,  88.36      ,  88.82      ,\n",
       "       103.63      ,  96.92      ,  78.225     , 132.7       ,\n",
       "        90.86      ,  90.88      ,  93.52      , 102.17      ,\n",
       "        91.61      , 115.88      , 105.03      ,  94.92      ,\n",
       "        94.4       ,  98.97      , 118.33      , 115.92      ,\n",
       "        85.76      ,  85.48      ,  74.17      ,  88.26      ,\n",
       "        90.6       ,  97.32      ,  97.57      ,  90.035     ,\n",
       "       107.48      ,  90.44      , 139.08      , 112.55      ,\n",
       "        89.23      , 109.43      , 100.74      , 112.19      ,\n",
       "       147.72      ,  88.38      , 100.49      ,  89.06      ,\n",
       "        91.14      ,  94.39      ,  85.2       ,  87.65      ,\n",
       "       113.31      , 108.97      ,  87.63      ,  91.13      ,\n",
       "        92.76      ,  93.        ,  85.74      ,  88.92      ,\n",
       "        90.01      , 108.35      , 100.32      , 100.57      ,\n",
       "       114.53      , 109.645     , 115.73      ,  85.97      ,\n",
       "       106.35      ,  92.53      , 104.52      , 104.97      ,\n",
       "        88.1       , 118.53      , 110.35      ,  87.99      ,\n",
       "        87.13      , 116.55      , 111.49      ,  91.91      ,\n",
       "        89.19      ,  93.31      , 104.065     ,  85.97      ,\n",
       "       119.5       , 102.76      ,  93.32      ,  94.21      ,\n",
       "        92.59      , 117.36      ,  96.38      , 115.42      ,\n",
       "        99.01      , 111.345     ,  91.63      ,  92.4       ,\n",
       "       112.32      ,  87.61      , 124.17      ,  92.52      ,\n",
       "        88.4       ,  97.89      ,  87.28      ,  89.06      ,\n",
       "       111.22      , 109.1       , 135.53      , 107.9       ,\n",
       "       106.54      ,  91.85      , 107.385     ,  91.63      ,\n",
       "       132.59      ,  88.72      ,  89.73      , 122.28      ,\n",
       "       117.81      ,  92.45      , 110.66      , 113.43      ,\n",
       "        90.01      , 112.41      , 100.74      , 115.75      ,\n",
       "       117.52      ,  88.03      , 111.86      , 125.        ,\n",
       "       111.59333333,  97.36      , 109.33      ,  94.81      ,\n",
       "       108.8       ,  91.13      , 113.75      ,  93.295     ,\n",
       "        84.48      , 111.1       ,  74.87      ,  88.03      ,\n",
       "        90.62      , 107.73      ,  93.45      , 112.        ,\n",
       "       102.77      , 110.53      ,  88.91      ,  84.48      ,\n",
       "        88.88      , 113.93      ,  90.75      , 113.93      ,\n",
       "       112.94      , 119.87      , 129.45      , 127.91      ,\n",
       "       109.09      ,  90.72      ,  91.63      , 105.87      ,\n",
       "        93.25      ,  92.97      , 108.54      ,  97.86      ,\n",
       "       105.97      ,  86.66      , 111.1       , 122.22      ,\n",
       "        90.11      ,  89.46      , 116.16      , 109.05      ,\n",
       "       109.16      ,  90.53      , 108.51      , 102.77      ,\n",
       "       102.6       , 105.64      , 111.1       ,  87.16      ,\n",
       "       106.79      , 265.32      ,  78.225     ,  97.86      ,\n",
       "       111.22      , 108.6       , 109.22      ,  92.53      ,\n",
       "        88.6       , 112.99      ,  85.55      , 111.345     ,\n",
       "       102.77      , 105.73      ,  93.62      , 111.59333333,\n",
       "        89.09      ,  98.02      , 110.88      , 122.51      ,\n",
       "       100.95      ,  90.62      ,  89.22      ,  94.62      ,\n",
       "        90.72      , 119.35      ,  98.01      ,  74.17      ,\n",
       "       111.59333333,  98.45      ,  90.72      , 106.9       ,\n",
       "        84.86      , 100.59      ,  87.61      , 115.18      ,\n",
       "       113.86      ,  73.02      , 104.18      , 106.19      ,\n",
       "       160.87      ,  95.22      , 111.59333333, 100.67      ,\n",
       "        93.12      ,  89.35      , 109.755     ,  98.37      ,\n",
       "       108.595     , 114.37      ,  91.7       , 103.63      ,\n",
       "       116.61      ,  93.59      ,  89.02      ,  92.19      ,\n",
       "        92.97      , 103.46      ,  86.8       , 106.19      ,\n",
       "       125.84      ,  91.63      ,  90.94      , 117.98      ,\n",
       "        93.65      ,  89.51      ,  93.62      ,  75.82      ,\n",
       "        89.2       ,  90.84      ,  90.63      ,  91.23      ,\n",
       "       102.93      , 103.63      ,  95.56      , 107.385     ,\n",
       "        88.13      , 106.02      ,  89.46      , 128.58      ,\n",
       "       108.2       , 154.43      , 118.53      ,  91.91      ,\n",
       "        92.17      ,  92.18      ,  89.69      ,  97.71      ,\n",
       "        76.96      ,  98.765     ,  95.87      , 106.51      ,\n",
       "       113.93      , 111.02      , 117.67      ,  98.24      ,\n",
       "        94.05      ,  98.28      ,  99.84      , 112.94      ,\n",
       "       111.83666667,  99.99      , 101.13      , 118.24      ,\n",
       "        95.65      , 106.6       , 133.36      ,  95.73      ,\n",
       "       106.1       ,  99.03      , 110.89      ,  91.66      ,\n",
       "        92.01      ,  99.52      , 107.53      ,  86.81      ,\n",
       "       105.08      , 116.34      ,  92.04      ,  91.79      ,\n",
       "       103.11      ,  93.02      , 112.        , 112.8       ,\n",
       "       131.56      , 108.03      , 100.54      ,  98.02      ,\n",
       "        92.91      ,  94.83      , 116.13      , 110.8       ,\n",
       "       105.35      ,  93.33      , 107.01      , 115.42      ,\n",
       "        88.38      , 108.68      ,  88.32      , 111.59      ,\n",
       "        92.63      ,  97.02      , 110.63      ,  90.06      ,\n",
       "        90.62      , 117.35      ,  88.83      , 104.36      ,\n",
       "       109.94      ,  95.67      , 128.94      , 108.33      ,\n",
       "        98.765     ,  94.95      ,  99.82      ,  89.97      ,\n",
       "        88.2       ,  90.05      , 114.21      ,  73.02      ,\n",
       "       110.65      ,  90.04      , 110.85      ,  95.59      ,\n",
       "       108.99      ,  89.22      ,  95.38      , 108.72      ,\n",
       "        90.06      , 102.08      , 109.74      , 101.76      ,\n",
       "       109.31      , 128.35      , 112.28      , 116.42      ,\n",
       "       114.78      ,  95.1       , 112.26      , 105.53      ,\n",
       "        91.385     , 113.74      ,  92.97      , 104.55      ,\n",
       "       108.8       , 127.19      ,  86.38      , 110.92      ,\n",
       "       127.91      , 103.32      , 105.59      , 111.345     ,\n",
       "        93.32      ,  90.69      ,  93.59      ,  87.57      ,\n",
       "       114.88      ,  91.385     ,  87.87      ,  98.17      ,\n",
       "       114.6       ,  97.96      , 122.47      ,  92.83      ,\n",
       "        87.99      ,  94.07      , 109.05      , 104.18      ,\n",
       "        80.44      ,  90.86      , 109.13      , 107.385     ,\n",
       "       116.73      , 106.91      , 105.89      , 102.65      ,\n",
       "        90.86      ,  88.92      ,  74.87      , 110.43      ,\n",
       "       108.93      , 141.39      ,  75.65      ,  96.38      ,\n",
       "        90.62      ,  90.57      , 107.96      ,  91.78      ,\n",
       "       110.35      ,  94.31      , 105.87      , 110.89      ,\n",
       "        93.74      , 107.35      ,  93.45      ,  91.23      ,\n",
       "       100.9       , 117.71      , 106.77      , 108.8       ,\n",
       "       114.095     ,  98.85      ,  94.64      ,  93.81      ,\n",
       "        97.68      , 107.48      , 106.19      , 108.88      ,\n",
       "        87.21      , 116.93      , 107.85      , 109.645     ,\n",
       "       121.84      ,  84.84      , 109.51      , 120.9       ,\n",
       "       114.46      , 108.16      ,  73.74      , 101.26      ,\n",
       "        78.71      , 109.1       , 105.79      , 105.34      ,\n",
       "       107.055     ,  73.74      ,  98.12      ,  92.64      ,\n",
       "       108.01      ,  76.99      ,  92.38      ,  96.41      ,\n",
       "       107.62      ,  89.06      , 111.64      , 110.52666667,\n",
       "        74.77      ,  94.92      ,  93.52      , 110.35      ,\n",
       "        88.92      ,  73.24      , 109.33      ,  91.84      ,\n",
       "        88.11      , 112.06      ,  94.9       , 118.74      ,\n",
       "       107.57      ,  88.66      , 106.13      , 116.16      ,\n",
       "       103.96      , 128.36      ,  99.15      ,  88.79      ,\n",
       "       107.5       ,  89.42      , 108.79      ,  96.38      ,\n",
       "       115.31      ,  91.19      ,  98.97      ,  91.02      ,\n",
       "        98.02      ,  92.01      ,  95.96      , 139.07      ,\n",
       "       114.4       ,  89.79      , 113.31      ,  95.7       ,\n",
       "        89.6       ,  91.44      ,  87.84      ,  98.12      ,\n",
       "        88.77      ,  98.95      ,  96.53      ,  91.62      ,\n",
       "       110.37      , 114.85      ,  74.75      , 100.83      ,\n",
       "       111.15      ,  99.2       , 110.21      , 111.345     ,\n",
       "       118.41      ,  93.83      ,  89.19      , 112.2       ,\n",
       "       108.        , 110.89      , 115.6       ,  93.33      ,\n",
       "       122.22      , 115.88      ,  92.32      , 110.43      ,\n",
       "        89.6       , 108.37      ,  91.59      ,  91.98      ,\n",
       "        92.74      ,  91.65      ,  94.08      ,  74.75      ,\n",
       "       146.3       , 106.16      ])"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_pred=dtree_reg.predict(cat_encd_test_final)\n",
    "y_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "74ac3d1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.041340950157426004"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtree_reg.score(cat_encd_test_final,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "a3757ceb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_reg=LinearRegression()\n",
    "lin_reg.fit(cat_encd_train_final,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "0935349e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred_lnr=lin_reg.predict(cat_encd_test_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "c2879d16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2.0380099741629735e+21"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_reg.score(cat_encd_test_final,y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
